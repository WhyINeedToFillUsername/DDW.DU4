{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDW HW 4 - Social Network Analysis\n",
    "For CTU in Prague, by Antonín Karola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# read file\n",
    "lines = []\n",
    "\n",
    "with open('casts.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=';')\n",
    "    for row in readCSV:\n",
    "        lines.append(row[1:3])\n",
    "\n",
    "# use numpy array for easy array slicing\n",
    "data = np.array(lines)\n",
    "\n",
    "# for all rows in data, extract movies (column 0)/actors (col 1); remove duplicates using np.unique + order\n",
    "movies = np.unique(list(filter(None, data[:,0])))\n",
    "actors = np.unique(list(filter(None, data[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# create graph, create a node for each actor\n",
    "G=nx.Graph()\n",
    "\n",
    "for actor in actors:\n",
    "    if actor:\n",
    "        G.add_node(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dictionary: [movie] = [actor1, actor2, ...]\n",
    "moviesWithActors = dict(zip(movies, [None] * len(movies)))\n",
    "\n",
    "# map actors to the movie dictionary above\n",
    "for row in data:\n",
    "    movie = row[0]; actor = row[1]\n",
    "    if movie:\n",
    "        if not moviesWithActors[movie]:\n",
    "            moviesWithActors[movie] = [actor]\n",
    "        else:\n",
    "            moviesWithActors[movie].append(actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create edges between actors that appeared in the same movie\n",
    "for movie in moviesWithActors:\n",
    "    movieActors = moviesWithActors[movie]\n",
    "    for fromActor in movieActors:\n",
    "        i = 0\n",
    "        for toActor in movieActors[i:]:\n",
    "            if fromActor and toActor:\n",
    "                G.add_edge(fromActor, toActor)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export graph to gephi\n",
    "nx.write_gexf(G, \"export.gexf\")\n",
    "#nx.draw(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "## Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide general statistics about the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of nodes and edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16614"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nodes\n",
    "n = len(actors)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172188"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00282623300911202"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possibleEdges = n*(n-1)/2\n",
    "edges/possibleEdges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.number_connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide list of top key players using different centralities\n",
    "Identify key players using centrality measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s a:\t0.19930175164028172\n",
      "Humphrey Bogart:\t0.026003732017095046\n",
      "James Stewart:\t0.022632877866730874\n",
      "Gary Cooper:\t0.02239210257027629\n",
      "John Gielgud:\t0.02239210257027629\n",
      "John Carradine:\t0.022211521097935352\n",
      "Peter Lorre:\t0.02179016432913983\n",
      "C.Aubrey Smith:\t0.020405706374525975\n",
      "Henry Fonda:\t0.019623186661048578\n",
      "Burt Lancaster:\t0.018900860771684826\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "for key, value in sorted(nx.degree_centrality(G).items(), key=operator.itemgetter(1), reverse=True)[0:10]:\n",
    "    print(\"%s:\\t%s\" % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closeness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s a:\t0.47334397258147604\n",
      "Charlton Heston:\t0.36832541164881627\n",
      "John Gielgud:\t0.366879133608347\n",
      "John Carradine:\t0.3665439581315982\n",
      "Burt Lancaster:\t0.3663765999469707\n",
      "Henry Fonda:\t0.3657184972071195\n",
      "James Stewart:\t0.3650920657805791\n",
      "Humphrey Bogart:\t0.36309023012578007\n",
      "Robert Mitchum:\t0.3616942846566501\n",
      "Peter Lorre:\t0.3606615008282145\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(nx.closeness_centrality(G).items(), key=operator.itemgetter(1), reverse=True)[0:10]:\n",
    "    print(\"%s:\\t%s\" % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s a:\t0.34429277261378943\n",
      "Humphrey Bogart:\t0.008273686145191887\n",
      "Vincent Price:\t0.007787663365423353\n",
      "John Carradine:\t0.007038387205951536\n",
      "Jack Nicholson:\t0.006673278925380563\n",
      "Burt Lancaster:\t0.006558833266695104\n",
      "Charlton Heston:\t0.006133041525240112\n",
      "John Gielgud:\t0.005786799065031964\n",
      "Max vonSydow:\t0.00575501153303901\n",
      "Robert deNiro:\t0.005684354165728045\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(nx.betweenness_centrality(G).items(), key=operator.itemgetter(1), reverse=True)[0:10]:\n",
    "    print(\"%s:\\t%s\" % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigenvector Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s a:\t0.32574473945821847\n",
      "C.Aubrey Smith:\t0.08707091404834201\n",
      "John Carradine:\t0.08561343912976806\n",
      "James Stewart:\t0.08367120801307142\n",
      "John Gielgud:\t0.08140384894958089\n",
      "Peter Lorre:\t0.07888536941271428\n",
      "Gary Cooper:\t0.07783581126958793\n",
      "Basil Rathbone:\t0.07529313121494362\n",
      "Humphrey Bogart:\t0.07442858275700319\n",
      "Henry Fonda:\t0.07438018567991815\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(nx.eigenvector_centrality(G).items(), key=operator.itemgetter(1), reverse=True)[0:10]:\n",
    "    print(\"%s:\\t%s\" % (key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(18, 18))\n",
    "pos = nx.random_layout(G)\n",
    "nx.draw(G, pos, font_size=8, labels={v: str(v) for v in G},\n",
    "        cmap=plt.get_cmap(\"bwr\"), node_color=[nx.degree_centrality(G)[k] for k in nx.degree_centrality(G)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe top clusters/communities\n",
    "Identify clusters/communities in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import community\n",
    "communities_generator = community.girvan_newman(G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "sorted(map(sorted, next_level_communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networkx algorithm (above) ran too long, I used community detection in Gephi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modularity Report from Gephi:\n",
    "![Modularity Report from Gephi](Gephi/communities/communities-size-distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe „Kevin Bacon“ numbers\n",
    "Compute „Kevin Bacon“ number for each actor with selected key player\n",
    "- e.g. top actors with the highest/lowest number\n",
    "- average number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortestPathLengths = nx.single_source_shortest_path_length(G, 'Kevin Bacon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top 10 hightest (closest actors to Kevin Bacon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert Castle:\t6\n",
      "Paredes:\t6\n",
      "Antonia SanJuan:\t6\n",
      "Elisa Touati:\t6\n",
      "Marbel Verdu:\t6\n",
      "Maria deMederios:\t6\n",
      "Barbara Dennek:\t6\n",
      "Jacqueline Lecomte:\t6\n",
      "Henri Piccoli:\t6\n",
      "Ann Ruymen:\t5\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(shortestPathLengths.items(), key=operator.itemgetter(1), reverse=True)[0:10]:\n",
    "    print(\"%s:\\t%s\" % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top 10 lowest (most distant actors from Kevin Bacon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kevin Bacon:\t0\n",
      "Tom Cruise:\t1\n",
      "Jack Nicholson:\t1\n",
      "Demi Moore:\t1\n",
      "s a:\t1\n",
      "J.A. Preston:\t1\n",
      "Michael deLeon:\t1\n",
      "Kiefer Sutherland:\t1\n",
      "Evan Rachel:\t1\n",
      "Mary Stuart Masterson:\t1\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(shortestPathLengths.items(), key=operator.itemgetter(1), reverse=False)[0:10]:\n",
    "    print(\"%s:\\t%s\" % (key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise important aspects of the analysis\n",
    "Insert visualisations from networkx/Gephi (images/screenshots)\n",
    "- for visualisation you can use only subset of actors/movies e.g. movies from specific category, movies with max 5 actors etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">TODO</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert a file with the graph exported to a GEXF format\n",
    "All computed values should be present as attributes\n",
    "- see `export.gefx` on the GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "**issues during the design/implementation**\n",
    "- The hardest part was to find out how to process the CSV file to make a graph from the data - how to map a list of actors in a movie to nodes with edges (result is 3 nested for loops)\n",
    "- Centralities took too long to calculate (like 20 min, due to the huge data set)\n",
    "- The same goes for finding communities in the graph (`girvan_newman` method internally uses `networkx.edge_betweenness_centrality()`)\n",
    "\n",
    "\n",
    "**ideas for extensions/improvements/future work**\n",
    "- filter invalid values from data (e.g. actor name \"s a\"...)\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
